Time:       Afternoon - TBD
Duration:   3 hours
Venue:      CIP-Pool
Capacity:   up to 20-30 participants

Title: Introduction to Hands-on Machine Learning with R

# === Flow === #
# Opening (10 min)
1. Purpose:
    i) Introducing a toolkit for machine learning with ease to read and visualize
    ii) why R -> community, leader in statistical analysis and visio, packages
2. Reference to R for Data Science (Wickham, Cetinkaya-Rundel and Grolemund)
3. Maybe R Basics cheat sheet as handout / intro / group participants based on prior knowledge?



# Intro (20 min)
4. Data structures in R, functions, flow-control, ggplot2, data reading and handling
5. Workflow of analysis: data -> explore -> (preprocess) -> model -> evaluate -> interpret
6. Introduction of the example data that will be used.

    Medical Condition Prediction Dataset - https://www.kaggle.com/datasets/marius2303/medical-condition-prediction-dataset
    Red Wine Quality - https://www.kaggle.com/datasets/marius2303/medical-condition-prediction-dataset
        Two groups for Random Forest vs MLR



# ML (20 min)
7. Data split
    For generalizability, enough data for training but very large datasets may give minimal gains, smaller for computation speed, if features >= sample_size you need to increase sample size to identify consistent signals
    Simple sampling vs stratified sampling: Check for the y/response variable.
    Class imbalances an be remedied by
        up-sampling: create rare class instances by repetition or bootstrapping
        down-sampling: choose a subsample of abundant class to match the size of rare class.
8. Evaluation
    Chapter 2.6 of *Hands-On ML with Râ€‹*

# Tasks
. Regression (30 min)
    Key words: predictor-response or explanatory-dependent variables, coefficients, intercept, slope,
                residuals, R-squared, RMSE, overfit/underfit
    R: lm(), summary(), predict()
    Demo:
    Task:

    ----- Break (10 min) -----

. Classification (30 min)
    Key words: categorical outcome, binary vs multiclass, logistic regression, decision tree, confusion matrix,
                accuracy-precision-recall and ROC-AUC vs Precision-Recall, F1 score
    R: glm(), rpart(), caret::confusionMatrix() or table()
    Demo:
    Task:
. Clustering/PCA (30 min)
    Key words: unsupervised learning, distance metrics (Euclidean, Manhattan), k-means, dendrogram,
                dimensionality reduction, PCA, principal components, variance explained
    R: kmeans(), prcomp(), ggplot2
    Demo:
    Task:
    Which step would PCA replace in the general procedure? -> "filter out non-informative features without manually removing them"

Closing (10 min)
. Summarize
. Further Reading:
    Feature Engineering and Selection: A Practical Approach for Predictive Models [http://www.feat.engineering/]

+ 20 mins buffer

(sums up to 3 hours)
